lsb_release -i -r
Print vendor and version information of linux distribution.

iostat -xk 5
Checks the i/o utilization.

find / -type f -size +1000k | xargs -n 1 ls -l --block-size=M
Find all files over 1000 kbs and then print the size of each of those
files in mbs.

sudo find / -maxdepth 1 -type d | xargs sudo du -hs
sudo find /var -maxdepth 1 -type d | xargs sudo du -hs
sudo find /var/lib -maxdepth 1 -type d | xargs sudo du -hs
This command is useful to explore if some directory or file is the major contributor to partition
exhaustion.  Starting from '/', examine which folders are using the most space and traverse to the
culprit.

free -g | grep Mem | tr -s " " | cut -d " " -f 2,3 | tr " " "/"
free | grep Mem | awk '{print $3/$2 * 100.0}'
knife ssh "name:gl*vm* OR name:sqe*vm*" "free -g | grep Mem | tr -s \" \" | cut -d \" \" -f 2,3,4" -a ipaddress --concurrency 5
When used with knife ssh, a quick way to see which hosts might be able to give back memory.

sudo lsof -a +L1 /
Show all the files in '/' with a link count less than 1, that is, deleted files.
If not there, sudo yum -y install lsof.

find . -mtime +10 | xargs -n 1 --no-run-if-empty rm -v
Remove files older than 10 days.  The -n 1 ensure that if there are large numbers of files the
rm command won't be too long, instead a new command will be created for each file.

fallocate -l 11M /var/log/HsmProxy.log
Create a 11 megabtype file.

df -h
Print disk usage.

du -hs <directory>
Print disk usage of some directory, recursive.


sudo chef-shell -z
Runs shell with chef variables loaded like irb.

ps -eo pcpu,pid,user,args | sort -k 1 -r | head -5
Print top 5 cpu consumers.  Running this command through knife ssh can yield results for lots of
processes.  Any that have a value greater than 100 typically means they are spinning on a core.  The
'uptime' command will print the overall cpu load which is also useful when trying to track down high
cpu consumption.
knife ssh "(chef_environment:int-dev* OR chef_environment:int-stage* OR chef_environment:int-sqe*) AND (NOT chef_environment:int-dev-jenkins) (NOT chef_environment:*perf*) AND name:*vm* AND (NOT creation_info_machine_origin:temp_hive)" "uptime" -a ipaddress --concurrency 20 | grep -v "load average: 0."

Splunk search
sourcetype=compliance_logs "Compliance Elapsed Time" seconds>6000


lsof
Print open files (which may not be shown in find or ls if the file
has been deleted, but a file descriptor is still open).

dd of=/path/to/file if=/dev/null bs=1GB count=10
Create a 10GB file with all zeros.

for node in gla0srv123 gla0srv35 gla0srv37 gla0srv124; do knife node show $node -a name -a tags -a chef_environment -a run_list; done
One line for loop to execute the same command multiple times.

ls | xargs -n 1 -i echo \{\}, | xargs -n 4
This command is to illustrate some features of xargs.  The \{\} combined
with -i allow the output from the piped command to be inserted in the
middle of the command xargs is building.  The -n allows some number of
inputs to be combined together.  This will print four items separated
by commas on each line.

abrt-cli list -f | grep Directory | cut -d" " -f 7 | xargs -i -n 1 sh -c 'echo directory {} has UUID; cat {}/uuid; echo '
This command will print all the abrt directories and and a file in the directory.
It uses sh -c to use the directory for 2 commands.

knife search "recipe:zookeeper AND environment:dev" -a ipaddress | grep ipaddress | tail -1 | tr -s " " | cut -d":" -f 2
Similar to other cut examples, but this one uses the tr command to trim extra whitespace to assist cut.

Find the contact info of all the teams who use java.
ff install_jdk | cut -d"/" -f 5 | sort | uniq | grep -v jdk | xargs -n 1 -i grep email deploy/chef/cookbooks/\{\}/attributes/contact_info.rb

ttknife search node "chef_environment:int-dev-cert" -a ipaddress |  grep ipaddress  | tr -s " " | cut -d" " -f 3 | xargs -n 1 -i ping -c 5 -q \{\} | grep -iE "statistics|packet"
Search for nodes in int-dev-cert that are not running.

ttknife search node "chef_environment:int-dev-sparepool" -a name | grep name | grep ip- | grep -v 10-203-0-74 | tr -s " " | cut -d" " -f 3 | xargs -n 1 -i knife client delete \{\} --yes
ttknife search node "chef_environment:int-dev-sparepool" -a name | grep name | grep ip- | grep -v 10-203-0-74 | tr -s " " | cut -d" " -f 3 | xargs -n 1 -i knife node delete \{\} --yes

Find all cookbook that depend on ps_client and trim them down.  Then determine their build targets.

eknife search node "deployed_cookbooks:ps_client" -a expanded_run_list --no-color | grep default | grep -v "base::default" | sed 's/::default//' | sort | uniq

eknife search node "deployed_cookbooks:ps_client AND chef_environment:ext-prod-*" -a expanded_run_list --no-color | grep "::" | grep -v "base::default" | sed 's/::default//' | sed -E 's/::.*//' | sort | uniq | tr -s " "

Find all the cookbook emails.
find deploy/chef/cookbooks -name contact_info.rb | xargs grep email | cut -d"=" -f 2 | sed 's/"//' | sed 's/"//' | sort | uniq | xclip

Similar to the command above, but also include the cookbooks.
for COOKBOOK in `find deploy/chef/cookbooks -name contact_info.rb` ; do cb=`echo $COOKBOOK | sed s:deploy/chef/cookbooks/::g | sed s:/attributes/contact_info.rb::g`; email=`echo $COOKBOOK | xargs grep email | cut -d"=" -f 2 | sed 's/"//' | sed 's/"//' | sort | uniq`; echo $cb,$email; done

Delete a collection of nodes in the sparepool.

g glog | grep -E "(17cbad3|release-15.6.1)"
Example of grep through git log with regular expression.


rm ~/clients.txt; rm ~/nodes.txt; ttknife client list > ~/clients.txt; ttknife node list > ~/nodes.txt; diff ~/nodes.txt ~/clients.txt | grep "> " | cut -d" " -f 2 | grep ip- | xargs -n 1 -i knife client delete \{\} --yes
Delete a collection of clients for which the node has been deleted and start with ip-.

rm ~/clients.txt; rm ~/nodes.txt; ttknife client list > ~/clients.txt; ttknife node list > ~/nodes.txt; diff ~/nodes.txt ~/clients.txt | grep "> "
Show the client objects that exist, but have no node object.

echo -n `date +"%Y-%m-%d-%H-%M-%S"`; git log --abbrev-commit --graph --date-order --date=relative --pretty=oneline | head -1 | sed -e 's/^*[ \t]*/_/g' | sed 's/\ /_/g' | sed 's/[^a-zA-Z0-9_]//g'
Simple sed usage example.  Format the latest git log in a particular format.

find deploy/chef/cookbooks/pds_* -name contact_info.rb -exec sed -i 's/email"] = ""/email"] = "email@tradingtechnologies.com"/g' {} \;
find deploy/chef/cookbooks/pds_* -name contact_info.rb -exec sed -i 's/pagerduty"] = ""/pagerduty"] = "Prices"/g' {} \;

for COOKBOOK in algoserver_exec algoserver_debug orderd orderd_remote pricefs priceproxy ttsdk ; do find deploy/chef/cookbooks/$COOKBOOK -name contact_info.rb -exec sed -i 's/email"] = ""/email"] = "email@tradingtechnologies.com"/g' {} \; && find deploy/chef/cookbooks/$COOKBOOK -name contact_info.rb -exec sed -i 's/pagerduty"] = ""/pagerduty"] = "Algo Server"/g' {} \; ; done

sed -i 's/replaceme/withme/g' file
Replace all occurences of 'replaceme' with 'withme' in 'file'.

Find and replace text in files.


If 6875cae through 2e02f97 (including both endpoints) are the commits I want to cherry pick,
then 6875cae^..2e02f97 is the option to 'git cherry-pick'.
git fetch
git log master --format=format:%H --grep DEB-76400 -n 1 ==> gives me the final commit that contains DEB-76400
git log master--format=format:%H --grep DEB-76400 -n 1 --reverse ==> gives me the final commit that contains DEB-76400

Needs more investigation: After merging a branch into develop, the push to origin/develop fails
because someone else beat me to it.  John suggests the following commands to avoid the bad merge
that results from a 'git pull':
git fetch
git rebase -p origin/develop
John also suggests that rerere needs to be enabled to remember the conflict resolution in the
case that the merge had many conflicts that would be painful to resolve again after the rebase.

grep af1518ac-c801-438e-b70d-4fc59e67a079 `lsoc bb1` | sed 's/.*order_sequence: //g' | sed 's/correlation_cl_ord_id.*//g' | sort | uniq --repeated
grep -c af1518ac-c801-438e-b70d-4fc59e67a079 `lsoc bb1` | sed 's/.*order_sequence: //g' | sed 's/correlation_cl_ord_id.*//g'
Command to parse log file for GUID and filter out most of the message.  the first sed removes everything before 'order_sequence: ' and
the second sed removes everything after.  The resuls are then sorted and passed to uniq to check for repeated fields.  To verify no skipped
values, the second command gives the total number.

cat /dir/file | sed -n -e '/2017-04-11/,$p' | xclip -i
Send the contents of file to the clipboard once the string 2017-04-11 is encountered.

for i in {1..10}; do command; done
Run a command in a loop on the command line.

watch -n 5 ls -l
Repeat a command over and over every 5 seconds.

watch -n 1 ntpstat
Run a command over and over (once per second).  In this case the command will
indicate if ntp is synchronized.

service ntpd stop
ntpd -gq
service ntpd start
Those commands will force ntp to sync to the source regardless of the offset.

files=`aws s3 ls s3://deploy-debesys | grep debesys_ | tr -s " " | cut -d" " -f 4`
for old in $files; do
    echo old $old
    new=${old//debesys_/debesys-}
    echo new $new
    aws s3 mv s3://deploy-debesys/$old s3://deploy-debesys/$new
done
Rename all files in S3 with a new name based on a regular expression.

$($DEPLOYMENT_SCRIPTS_REPO_ROOT/run python $DEPLOYMENT_SCRIPTS_REPO_ROOT/deploy/chef/scripts/aws_authenticator.py --account deb --role dev --env)

$($DEPLOYMENT_SCRIPTS_REPO_ROOT/run python $DEPLOYMENT_SCRIPTS_REPO_ROOT/deploy/chef/scripts/aws_authenticator.py --account prod --role dev --env)

aws ec2 describe-images --filters "Name=description,Values=*ec2_instance.py*" --query 'Images[*].{AMI:ImageId,Name:Name,Description:Description,Creation:CreationDate,Snapshot:BlockDeviceMappings[*].Ebs.SnapshotId}' --region us-east-1
(add this to get the list of snapshots)
| grep snap- | tr -d "\"" | tr -s " " | tr "\n" " "
(add this to get the list of amis)
| grep ami- | cut -d":" -f 2 | tr -d "\"" | tr -d "," | tr "\n" " "

(aws ec2 deregister-image --region us-east-1 --image-id)
for AMI_ID in a1 a2; do aws ec2 deregister-image --region -1 --image-id $AMI_ID; done

(aws ec2 delete-snapshot --region us-east-1 --snapshot-id)
for SNAP_ID in s1 s2; do aws ec2 delete-snapshot --region -1 --snapshot-id $SNAP_ID; done

abrt-cli list -f | grep Directory | cut -d" " -f 7 | xargs -n 1 abrt-cli rm

curl http://ipecho.net/plain
Get the external IP address of some host as seen by the Internet.

knife node delete NODE_NAME
knife client delete NODE_NAME
rpm -q chef
rpm -e chef-11.4.4-2.el6.x86_64;rm -rf /var/chef/; rm -rf /etc/chef/; rm -rf /opt/chef

vcloud -l user -o Controlled_Deployment | grep gla | cut -f 1 | xargs -n 1 knife node show
Show all the vms I own in the Controlled_Deployment vcloud organization.

coredumps
---------
kernel.core_pattern = /tmp/core
kernel.core_uses_pid = 1
Creates core files like /tmp/core.pid, separate from abrt.

date time timezone
------------------
set the date and time
date -s "2 OCT 2006 18:00:00"


jenkins
-------
curl -u tweiss:<token> https://jenkins.tradingtechnologies.com/job/backend-deployment/9571/consoleText > /tmp/file.log
Get a jenkins log and write to a local file.


git
---
git log --graph --date-order --abbrev-commit --pretty=format:"%h - %an, %ar : %s" > ~/glog.txt
Print git log to a file.

git clean -fn
Remove all untracked files (-n for dry run).

                 (bad)                                    (good)
git bisect start 5666bedf39bff85dd208be0e905681cafd303fd5 f8928e3
chmod +x ~/githome/git_bisect_make.sh
git bisect run ~/githome/git_bisect_make.sh
(commit should be the one which transitioned from good to bad)
git bisect reset (when done)

git reset --hard HASH~
Make HEAD move to HASH previous hash.

git tag -d $(git tag); git fetch
Delete all the tags and re-grab them from origin.

To create a local origin:
git clone git@github.com:tradingtechnologies/debesys.git --mirror fake_remote
You can't do much with this repo except clone from it.

git clone file:///home/tweiss/dev-root/fake_remote/ 1_local_remote && cd 1_local_remote && git submodule update --init --recursive
(then git submodule init/update; note that the submodules still point back
 to original origin)

git clone file:///home/tweiss/dev-root/fake_remote/ 2_local_remote && cd 2_local_remote && git submodule update --init --recursive
Why two clones?  That way you can push from one, then pull from the other
to verify your changes are getting pushed as expected.

git diff branch1:dir/file branch2:dir/file
Compare file across branches.

git --no-pager log --grep="bump cookbook versions" --pretty=format:'%ae' | grep -E "trade.tt|tradingtechnologies.com" | sort | uniq | tr '\n' ';'
Find commiters.


tcpdump
-------
tcpdump -D
Lists all the interfaces, the number is used for -i on future commands.

tcpdump -i 1 dst 10.140.18.67 and port 16058
Show all messages from destination and port.

tcpdump -i 1 host 10.140.18.67 and port 16058
Show all message to and from ip and port.

sudo tcpdump -vvv -s 0 -i 6 -n port 53
Show all DNS lookups on the current machine.

Wireshark Filters
-----------------
ip.src == 10.140.18.67 || ip.dst == 10.140.18.67


Xming
-----
Steps to set up X11 forwarding from RHEL to Windows.
- Install Xming from sourceforge.net/project/xming (default installation).
- Install Xmingfonts sourceforge.net/projects/xming/files (required for emacs).
- Install putty.
- Install puttygen.
- In putty configure the following settings:
  - Session -> Saved Sessions Give the session a name
    and save/load it to make sure the rest are not lost.
  - Connection -> Data -> Auto-login username 'debesys'
    (or whatever username you want to log in with)
  - Connection -> Seconds between keep alive 120
  - If no existing public/private key pairs exist, create a new
    pair on the linux machine with the command:
    ssh-keygen -t rsa -C "Tom.Weiss@TradingTechnologies.com -f ~/.ssh/windows_to_linux
  - Copy private key from linux machine into c:\Users\USER\.ssh\tmp_key
    Put the public key in ~/.ssh/authorized_keys on linux host.
    Launch puttygen.
    Select Conversions Menu.
    Open the c:\Users\USER\.ssh\tmp_key file.
    Select the 'Save private key' button and name with extension .ppk.
    SSH -> Auth -> Private key file for authentication -> Browse to the
    ppk file just created.
   - X11 -> Enable X11 Forwarding.
  - Session -> Host <IP of host>
  - Potential X11 Performance Improvements outlined here:
    http://xmodulo.com/2013/07/how-to-speed-up-x11-forwarding-in-ssh.html
    Under Connection -> SSH -> Check Enable Compression
    Under Encryption Options -> Choose Arcfour then Blowfish.
  - Save.

View a file's permissions as numbers.
stat -c '%a' [file]

ssh
---
View fingerprint:
ssh-keygen -lf ~/.ssh/id_rsa.pub

Customize keys used per host via ~/.ssh/config:
Host *github.com
     IdentityFile ~/.ssh/github_rsa
     User git

gnome
-----
I believe that for some of these changes, the user needs to log out for them to take effect.
To stop cursor from blinking launch gnome-keyboard-properties and uncheck cursor blinking textbox,
use --get to view the current settings.  This command works on versions >= 2.31.3:
gconftool-2 --set /desktop/gnome/interface/cursor_blink --type boolean False
gconftool-2 --set /apps/gnome-terminal/profiles/Default/cursor_blink --type boolean False
gconftool-2 --set /apps/gnome-terminal/profiles/Default/cursor_blink_mode --type string off
General -> Font: Monospace 14
Check 'Use custom default terminal size' 200 columns 25 rows
Colors -> Text Color: #10F015
Colors -> Background Color: #000000
Scrolling -> check Unlimited
To prevent function keys from being caught in emacs -nw mode, open the Keyboard Shortcuts
and uncheck "Enable the menu shortcut key (F10 by default).  Then go through all the
shortcuts and use backspace in combination with clicking to disable the shortcuts mapped
to function keys.
gnome-about --gnome-version to get the version of gnome.


selinux
-------
getenforce
setenforce
/etc/selinux/config
chcon -v -R type=var_log_t /dir1/dir2 (change label)
ls -Z <file> (view label)

yum
---
sudo yum provides /bin/ls
Indicates which package provides a file.

yum list installed
Shows which packages are installed.

sudo yum repolist
Shows which repos are used for installed packages.

yum search package
Shows more details about packages.

rpm -q --queryformat "%{EPOCH} : %{NAME} - %{VERSION} - %{RELEASE} . %{ARCH}\n" gdb
Query local machine for information about which gdb is installed.

repoquery -q --queryformat "%{EPOCH} : %{NAME} - %{VERSION} - %{RELEASE} . %{ARCH}\n" gdb
Query repos in /etc/yum.repos.d/ for packages.

networking
----------
Disable ip messaging from local machine to some ip address (e.g., 10.203.0.43).
sudo service iptables start
sudo iptables -A OUTPUT -d "10.203.0.43" -j DROP
sudo iptables -D OUTPUT -d "10.203.0.43" -j DROP
sudo service iptables stop

(stop networking for a while)
sudo service iptables start; sudo iptables -A OUTPUT -d "10.203.0.43" -j DROP; sleep 60; sudo iptables -D OUTPUT -d "10.203.0.43" -j DROP; sudo service iptables stop

Physical ports can be in one of two modes:
1) access (a.k.a., untagged, single vlan)
2) trunk (a.k.a., vlan tagging, dot1q, 802.1q, multiple vlan, multiple layer 3 interfaces)

ifconfig
Prints network information.
ethN is a physical port.  If there is a IPV4 address then the port is in access
mode.  Otherwise the port is in trunk mode.  If you examine the MAC of a vlan
it will correspond to the MAC of one of the physical ports, which is the port
being used by the vlan.

/etc/sysconfig/network-scripts/ifcfg-X
Each file describes a layer 3 interface available to the operating system.

ethtool ethN
Another way to get information about an interface.

lldptool -tnl ethN
(yum install TT-LLDP-SETUP --nogpgcheck)
Package created to provide extra information about switch connections.

/etc/udev/rules.d/70-persistent-net.rules
Contains configuration which maps ethN names to MAC addresses.

ifup/ifdown
Bring an inteface up or down.  Check in /etc/sysconfig/network-scripts/ifcfg-X
for a list of all the interfaces.


VirtualBox
----------
VirtualBox Setup

System -> Motherboard -> 4GB RAM (depends on your needs)
System -> Processor -> 4 CPUs (depends on your needs)
Network -> Adapter 1 -> NAT
Network -> Adapter 1 -> Port Forwarding (port 22 on host to port 22 on guest)
Network -> Adapter 1 -> Cable Connected (check box)
Storage -> Controller: IDE -> Click on disk to load the iso Centos isos are available here.  These instructions support the minimal iso, but are also appropriate to the live dvd iso.
Power On
Devices -> Shared Clipboard -> Bidirectional
Start the networking: ifup eth0


sudo yum -y install emacs
edit /etc/sysconfig/network-scripts/ifcfg-eth0 and make the contents:

DEVICE=eth0
TYPE=Ethernet
BOOTPROTO=dhcp
ONBOOT=yes
NM_CONTROLLED=no

After saving the file, restart the network with the command:
service network restart

yum -y groupinstall "Desktop" "Desktop Platform" "X Window System" "Fonts"
edit  /etc/inittab and change
id:3:initdefault:
to
id:5:initdefault:

create file /etc/sudoers.d/YOUR_USERNAME with contents:
YOUR_USERNAME  ALL=(ALL)     NOPASSWD: ALL

export PS1="\h \w ROOT \n>"Set root's prompt in .bashrc:
